<!DOCTYPE html>
<html lang="en"><head><title>Ethics and Technology by Herman Tavani</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=DM Serif Text:wght@400;700&amp;family=Noto Serif:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Ethics and Technology by Herman Tavani"/><meta property="og:description" content="Textbook site by Wiley is here. Table of Contents • CHAPTER 1: Introduction to Cyberethics: Concepts, Perspectives, and Methodological Frameworks Scenario 1–1: Hacking into the Mobile Phones of Celebrities 1.1 Defining Key Terms: Cyberethics and Cybertechnology • 1.1.1 What Is Cybertechnology? • 1.1.2 Why the Term Cyberethics? 1.2 The Cyberethics Evolution: Four Developmental Phases in Cybertechnology 1.3 Are Cyberethics Issues Unique Ethical Issues? • Scenario 1–2: Developing the Code for a Computerized Weapon System • Scenario 1–3: Digital Piracy • 1.3.1 Distinguishing between Unique Technological Features and Unique Ethical Issues • 1.3.2 An Alternative Strategy for Analyzing the Debate about the Uniqueness of Cyberethics Issues • 1.3.3 A Policy Vacuum in Duplicating Computer Software 1.4 Cyberethics as a Branch of Applied Ethics: Three Distinct Perspectives • 1.4.1 Perspective #1: Cyberethics as a Field of Professional Ethics • 1.4.2 Perspective #2: Cyberethics as a Field of Philosophical Ethics • 1.4.3 Perspective #3: Cyberethics as a Field of Sociological/Descriptive Ethics • Scenario 1–4: The Impact of Technology X on the Pleasantville Community 1.5 A Comprehensive Cyberethics Methodology • 1.5.1 A “Disclosive” Method for Cyberethics • 1.5.2 An Interdisciplinary and Multilevel Method for Analyzing Cyberethics Issues 1.6 A Comprehensive Strategy for Approaching Cyberethics Issues 1.7 Chapter Summary • CHAPTER 2: Ethical Concepts And Ethical Theories: Frameworks For Analyzing Moral Issues Scenario 2–1: The Case of the “Runaway Trolley”: A Classic Moral Dilemma 2.1 Ethics and Morality • 2.1.1 What Is Morality? • 2.1.2 The Study of Morality: Three Distinct Approaches for Evaluating and Justifying the Rules Comprising a Moral System 2.2 Discussion Stoppers as Roadblocks to Moral Discourse • 2.2.1 Discussion Stopper #1: People Disagree on Solutions to Moral Issues • 2.2.2 Discussion Stopper #2: Who Am I to Judge Others? • 2.2.3 Discussion Stopper #3: Morality Is Simply a Private Matter • 2.2.4 Discussion Stopper #4: Morality Is Simply a Matter for Individual Cultures to Decide • Scenario 2–2: The Price of Defending Moral Relativism 2.3 Why Do We Need Ethical Theories? 2.4 Consequence‐Based Ethical Theories • 2.4.1 Act Utilitarianism • Scenario 2–3: A Controversial Policy in Newmerica • 2.4.2 Rule Utilitarianism 2.5 Duty‐Based Ethical Theories • 2.5.1 Rule Deontology • Scenario 2–4: Making an Exception for Oneself • 2.5.2 Act Deontology • Scenario 2–5: A Dilemma Involving Conflicting Duties 2.6 Contract‐Based Ethical Theories • 2.6.1 Some Criticisms of Contract‐Based Theories • 2.6.2 Rights‐Based Contract Theories 2.7 Character‐Based Ethical Theories • 2.7.1 Being a Moral Person vs."/><meta property="og:image" content="https://robinsonraju.blog/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Textbook site by Wiley is here. Table of Contents • CHAPTER 1: Introduction to Cyberethics: Concepts, Perspectives, and Methodological Frameworks Scenario 1–1: Hacking into the Mobile Phones of Celebrities 1.1 Defining Key Terms: Cyberethics and Cybertechnology • 1.1.1 What Is Cybertechnology? • 1.1.2 Why the Term Cyberethics? 1.2 The Cyberethics Evolution: Four Developmental Phases in Cybertechnology 1.3 Are Cyberethics Issues Unique Ethical Issues? • Scenario 1–2: Developing the Code for a Computerized Weapon System • Scenario 1–3: Digital Piracy • 1.3.1 Distinguishing between Unique Technological Features and Unique Ethical Issues • 1.3.2 An Alternative Strategy for Analyzing the Debate about the Uniqueness of Cyberethics Issues • 1.3.3 A Policy Vacuum in Duplicating Computer Software 1.4 Cyberethics as a Branch of Applied Ethics: Three Distinct Perspectives • 1.4.1 Perspective #1: Cyberethics as a Field of Professional Ethics • 1.4.2 Perspective #2: Cyberethics as a Field of Philosophical Ethics • 1.4.3 Perspective #3: Cyberethics as a Field of Sociological/Descriptive Ethics • Scenario 1–4: The Impact of Technology X on the Pleasantville Community 1.5 A Comprehensive Cyberethics Methodology • 1.5.1 A “Disclosive” Method for Cyberethics • 1.5.2 An Interdisciplinary and Multilevel Method for Analyzing Cyberethics Issues 1.6 A Comprehensive Strategy for Approaching Cyberethics Issues 1.7 Chapter Summary • CHAPTER 2: Ethical Concepts And Ethical Theories: Frameworks For Analyzing Moral Issues Scenario 2–1: The Case of the “Runaway Trolley”: A Classic Moral Dilemma 2.1 Ethics and Morality • 2.1.1 What Is Morality? • 2.1.2 The Study of Morality: Three Distinct Approaches for Evaluating and Justifying the Rules Comprising a Moral System 2.2 Discussion Stoppers as Roadblocks to Moral Discourse • 2.2.1 Discussion Stopper #1: People Disagree on Solutions to Moral Issues • 2.2.2 Discussion Stopper #2: Who Am I to Judge Others? • 2.2.3 Discussion Stopper #3: Morality Is Simply a Private Matter • 2.2.4 Discussion Stopper #4: Morality Is Simply a Matter for Individual Cultures to Decide • Scenario 2–2: The Price of Defending Moral Relativism 2.3 Why Do We Need Ethical Theories? 2.4 Consequence‐Based Ethical Theories • 2.4.1 Act Utilitarianism • Scenario 2–3: A Controversial Policy in Newmerica • 2.4.2 Rule Utilitarianism 2.5 Duty‐Based Ethical Theories • 2.5.1 Rule Deontology • Scenario 2–4: Making an Exception for Oneself • 2.5.2 Act Deontology • Scenario 2–5: A Dilemma Involving Conflicting Duties 2.6 Contract‐Based Ethical Theories • 2.6.1 Some Criticisms of Contract‐Based Theories • 2.6.2 Rights‐Based Contract Theories 2.7 Character‐Based Ethical Theories • 2.7.1 Being a Moral Person vs."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Text-Books/Ethics-and-Technology"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">✍️ Rob's Notes</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="recent-notes desktop-only"><h3>Recent Notes</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../Readwise/Articles/2024-11-05---Smith---Four-Reasons-Not-to-Vote-for-Trump,-and-Four-Reasons-to-Vote-for-Harris" class="internal">2024-11-05 - Smith - Four Reasons Not to Vote for Trump, and Four Reasons to Vote for Harris</a></h3></div><p class="meta">Nov 10, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../Readwise/Articles/2024-11-05---Zaides---Engineering-Management-in-the-Next-Unicorn-App" class="internal">2024-11-05 - Zaides - Engineering Management in the Next Unicorn App</a></h3></div><p class="meta">Nov 10, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../Readwise/Articles/2024-11-03---Hitze---Big-Ideas,-Bad-Ideas,-and-Blunders" class="internal">2024-11-03 - Hitze - Big Ideas, Bad Ideas, and Blunders</a></h3></div><p class="meta">Nov 10, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../Readwise/Articles/2024-11-03---Smith---Trumpism-Is-Kakistocracy" class="internal">2024-11-03 - Smith - Trumpism Is Kakistocracy</a></h3></div><p class="meta">Nov 10, 2024</p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../Readwise/Articles/2024-11-02---Zaides---How-to-Start,-Run,-and-Sell-a-Bootstrapped-SaaS" class="internal">2024-11-02 - Zaides - How to Start, Run, and Sell a Bootstrapped SaaS</a></h3></div><p class="meta">Nov 10, 2024</p></div></li></ul></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../Text-Books/">Text Books</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Ethics and Technology by Herman Tavani</a></div></nav><h1 class="article-title">Ethics and Technology by Herman Tavani</h1><p show-comma="true" class="content-meta"><span>May 14, 2024</span><span>13 min read</span></p><ul class="tags"><li><a href="../tags/Information-Technology" class="internal tag-link">Information-Technology</a></li><li><a href="../tags/Ethics" class="internal tag-link">Ethics</a></li><li><a href="../tags/Non-Fiction" class="internal tag-link">Non-Fiction</a></li><li><a href="../tags/Textbook" class="internal tag-link">Textbook</a></li></ul></div></div><article class="popover-hint"><p>Textbook site by Wiley is <a href="https://www.wiley.com/en-us/Ethics+and+Technology%3A+Controversies%2C+Questions%2C+and+Strategies+for+Ethical+Computing%2C+5th+Edition-p-9781119239758" class="external">here<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<h2 id="table-of-contents">Table of Contents<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#table-of-contents" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>• CHAPTER 1: Introduction to Cyberethics: Concepts, Perspectives, and Methodological Frameworks</p>
<ul>
<li>Scenario 1–1: Hacking into the Mobile Phones of Celebrities</li>
<li>1.1 Defining Key Terms: Cyberethics and Cybertechnology
• 1.1.1 What Is Cybertechnology?
• 1.1.2 Why the Term Cyberethics?</li>
<li>1.2 The Cyberethics Evolution: Four Developmental Phases in Cybertechnology</li>
<li>1.3 Are Cyberethics Issues Unique Ethical Issues?
• Scenario 1–2: Developing the Code for a Computerized Weapon System
• Scenario 1–3: Digital Piracy
• 1.3.1 Distinguishing between Unique Technological Features and Unique Ethical Issues
• 1.3.2 An Alternative Strategy for Analyzing the Debate about the Uniqueness of Cyberethics Issues
• 1.3.3 A Policy Vacuum in Duplicating Computer Software</li>
<li>1.4 Cyberethics as a Branch of Applied Ethics: Three Distinct Perspectives
• 1.4.1 Perspective #1: Cyberethics as a Field of Professional Ethics
• 1.4.2 Perspective #2: Cyberethics as a Field of Philosophical Ethics
• 1.4.3 Perspective #3: Cyberethics as a Field of Sociological/Descriptive Ethics
• Scenario 1–4: The Impact of Technology X on the Pleasantville Community</li>
<li>1.5 A Comprehensive Cyberethics Methodology
• 1.5.1 A “Disclosive” Method for Cyberethics
• 1.5.2 An Interdisciplinary and Multilevel Method for Analyzing Cyberethics Issues</li>
<li>1.6 A Comprehensive Strategy for Approaching Cyberethics Issues</li>
<li>1.7 Chapter Summary</li>
</ul>
<p>• CHAPTER 2: Ethical Concepts And Ethical Theories: Frameworks For Analyzing Moral Issues</p>
<ul>
<li>Scenario 2–1: The Case of the “Runaway Trolley”: A Classic Moral Dilemma</li>
<li>2.1 Ethics and Morality
• 2.1.1 What Is Morality?
• 2.1.2 The Study of Morality: Three Distinct Approaches for Evaluating and Justifying the Rules Comprising a Moral System</li>
<li>2.2 Discussion Stoppers as Roadblocks to Moral Discourse
• 2.2.1 Discussion Stopper #1: People Disagree on Solutions to Moral Issues
• 2.2.2 Discussion Stopper #2: Who Am I to Judge Others?
• 2.2.3 Discussion Stopper #3: Morality Is Simply a Private Matter
• 2.2.4 Discussion Stopper #4: Morality Is Simply a Matter for Individual Cultures to Decide
• Scenario 2–2: The Price of Defending Moral Relativism</li>
<li>2.3 Why Do We Need Ethical Theories?</li>
<li>2.4 Consequence‐Based Ethical Theories
• 2.4.1 Act Utilitarianism
• Scenario 2–3: A Controversial Policy in Newmerica
• 2.4.2 Rule Utilitarianism</li>
<li>2.5 Duty‐Based Ethical Theories
• 2.5.1 Rule Deontology
• Scenario 2–4: Making an Exception for Oneself
• 2.5.2 Act Deontology
• Scenario 2–5: A Dilemma Involving Conflicting Duties</li>
<li>2.6 Contract‐Based Ethical Theories
• 2.6.1 Some Criticisms of Contract‐Based Theories
• 2.6.2 Rights‐Based Contract Theories</li>
<li>2.7 Character‐Based Ethical Theories
• 2.7.1 Being a Moral Person vs. Following Moral Rules
• 2.7.2 Acquiring the “Correct” Habits</li>
<li>2.8 Integrating Aspects of Classical Ethical Theories into a Single Comprehensive Theory
• 2.8.1 Moor’s Just‐Consequentialist Theory and Its Application to Cybertechnology
• 2.8.2 Key Elements in Moor’s Just‐Consequentialist Framework</li>
<li>2.9 Chapter Summary</li>
</ul>
<p>• CHAPTER 3: Critical Reasoning Skills for Evaluating Disputes in Cyberethics</p>
<ul>
<li>SCENARIO 3–1: Reasoning About Whether to Download Software from “Sharester”</li>
<li>3.1 What Is Critical Reasoning?
• 3.1.1 Some Basic Concepts: (Logical) Arguments and Claims
• 3.1.2 The Role of Arguments
• 3.1.3 The Basic Structure of an Argument</li>
<li>3.2 Constructing an Argument</li>
<li>3.3 Valid Arguments</li>
<li>3.4 Sound Arguments</li>
<li>3.5 Invalid Arguments</li>
<li>3.6 Inductive Arguments</li>
<li>3.7 Fallacious Arguments</li>
<li>3.8 A Seven‐Step Strategy for Evaluating Arguments</li>
<li>3.9 Identifying Some Common Fallacies
• 3.9.1 Ad Hominem Argument
• 3.9.2 Slippery Slope Argument
• 3.9.3 Fallacy of Appeal to Authority
• 3.9.4 False Cause Fallacy
• 3.9.5 Fallacy of Composition/Fallacy of Division
• 3.9.6 Fallacy of Ambiguity/Equivocation
• 3.9.7 The False Dichotomy/Either–Or Fallacy/All‐or‐Nothing Fallacy
• 3.9.8 The Virtuality Fallacy</li>
<li>3.10 Chapter Summary</li>
</ul>
<p>• CHAPTER 4: Professional Ethics, Codes of Conduct, and Moral Responsibility</p>
<ul>
<li>Scenario 4–1: Fatalities Involving the Oerlikon GDF‐005 Robotic Cannon</li>
<li>4.1 What Is Professional Ethics?
• 4.1.1 What Is a Profession?
• 4.1.2 Who Is a Professional?
• 4.1.3 Who Is a Computer/IT Professional?</li>
<li>4.2 Do Computer/IT Professionals Have Any Special Moral Responsibilities?</li>
<li>4.3 Professional Codes of Ethics and Codes of Conduct
• 4.3.1 The Purpose of Professional Codes
• 4.3.2 Some Criticisms of Professional Codes
• 4.3.3 Defending Professional Codes
• 4.3.4 The IEEE‐CS/ACM Software Engineering Code of Ethics and Professional Practice</li>
<li>4.4 Conflicts of Professional Responsibility: Employee Loyalty and Whistle‐Blowing
• 4.4.1 Do Employees Have an Obligation of Loyalty to Employers?
• 4.4.2 Whistle‐Blowing
• Scenario 4–2: NSA Surveillance and the Case of Edward Snowden</li>
<li>4.5 Moral Responsibility, Legal Liability, and Accountability
• 4.5.1 Distinguishing Responsibility from Liability and Accountability
• 4.5.2 Accountability and the Problem of “Many Hands”
• Scenario 4–3: The Case of the Therac‐25 Machine
• 4.5.3 Legal Liability and Moral Accountability</li>
<li>4.6 Do Some Computer Corporations Have Special Moral Obligations?</li>
<li>4.7 Chapter Summary</li>
</ul>
<p>• CHAPTER 5: Privacy and Cyberspace</p>
<ul>
<li>Scenario 5–1: A New NSA Data Center</li>
<li>5.1 Privacy in the Digital Age: Who Is Affected and Why Should We Worry?
• 5.1.1 Whose Privacy Is Threatened by Cybertechnology?
• 5.1.2 Are Any Privacy Concerns Generated by Cybertechnology Unique or Special?</li>
<li>5.2 What Is Personal Privacy?
• 5.2.1 Accessibility Privacy: Freedom from Unwarranted Intrusion
• 5.2.2 Decisional Privacy: Freedom from Interference in One’s Personal Affairs
• 5.2.3 Informational Privacy: Control over the Flow of Personal Information
• 5.2.4 A Comprehensive Account of Privacy
• Scenario 5–2: Descriptive Privacy
• Scenario 5–3: Normative Privacy
• 5.2.5 Privacy as “Contextual Integrity”
• Scenario 5–4: Preserving Contextual Integrity in a University Seminar</li>
<li>5.3 Why Is Privacy Important?
• 5.3.1 Is Privacy an Intrinsic Value?
• 5.3.2 Privacy as a Social Value</li>
<li>5.4 Gathering Personal Data: Surveillance, Recording, and Tracking Techniques
• 5.4.1 “Dataveillance” Techniques
• 5.4.2 Internet Cookies
• 5.4.3 RFID Technology
• 5.4.4 Cybertechnology and Government Surveillance</li>
<li>5.5 Analyzing Personal Data: Big Data, Data Mining, and Web Mining
• 5.5.1 Big Data: What, Exactly, Is It, and Why Does It Threaten Privacy?
• 5.5.2 Data Mining and Personal Privacy
• Scenario 5–5: Data Mining at the XYZ Credit Union
• 5.5.3 Web Mining: Analyzing Personal Data Acquired from Our Interactions Online</li>
<li>5.6 Protecting Personal Privacy in Public Space
• 5.6.1 PPI vs. NPI
• Scenario 5–6: Shopping at SuperMart
• Scenario 5–7: Shopping at Nile.com
• 5.6.2 Search Engines and the Disclosure of Personal Information</li>
<li>5.7 Privacy Legislation and Industry Self‐Regulation
• 5.7.1 Industry Self‐Regulation and Privacy‐Enhancing Tools
• 5.7.2 Privacy Laws and Data Protection Principles</li>
<li>5.8 A Right to “Be Forgotten” (or to “Erasure”) in the Digital Age
• Scenario 5–8: An Arrest for an Underage Drinking Incident 20 Years Ago
• 5.8.1 Arguments Opposing RTBF
• 5.8.2 Arguments Defending RTBF
• 5.8.3 Establishing “Appropriate” Criteria</li>
<li>5.9 Chapter Summary</li>
</ul>
<p>• CHAPTER 6: Security in Cyberspace</p>
<ul>
<li>Scenario 6–1: The “Olympic Games” Operation and the Stuxnet Worm</li>
<li>6.1 Security in the Context of Cybertechnology
• 6.1.1 Cybersecurity as Related to Cybercrime
• 6.1.2 Security and Privacy: Some Similarities and Some Differences</li>
<li>6.2 Three Categories of Cybersecurity
• 6.2.1 Data Security: Confidentiality, Integrity, and Availability of Information
• 6.2.2 System Security: Viruses, Worms, and Malware
• 6.2.3 Network Security: Protecting our Infrastructure
• Scenario 6–2: The “GhostNet” Controversy</li>
<li>6.3 Cloud Computing and Security
• 6.3.1 Deployment and Service/Delivery Models for the Cloud
• 6.3.2 Securing User Data Residing in the Cloud
• 6.3.3 Assessing Risk in the Cloud and in the Context of Cybersecurity</li>
<li>6.4 Hacking and “The Hacker Ethic”
• 6.4.1 What Is “The Hacker Ethic”?
• 6.4.2 Are Computer Break‐ins Ever Ethically Justifiable?</li>
<li>6.5 Cyberterrorism
• 6.5.1 Cyberterrorism vs. Hacktivism
• Scenario 6–3: Anonymous and the “Operation Payback” Attack
• 6.5.2 Cybertechnology and Terrorist Organizations</li>
<li>6.6 Information Warfare (IW)
• 6.6.1 Information Warfare vs. Conventional Warfare
• 6.6.2 Potential Consequences for Nations that Engage in IW</li>
<li>6.7 Chapter Summary</li>
</ul>
<p>• CHAPTER 7: Cybercrime and Cyber‐Related Crimes</p>
<ul>
<li>Scenario 7–1: Creating a Fake Facebook Account to Catch Criminals</li>
<li>7.1 Cybercrimes and Cybercriminals
• 7.1.1 Background Events: A Brief Sketch
• 7.1.2 A Typical Cybercriminal</li>
<li>7.2 Hacking, Cracking, and Counter Hacking
• 7.2.1 Hacking vs. Cracking
• 7.2.2 Active Defense Hacking: Can Acts of “Hacking Back” or Counter Hacking Ever Be Morally Justified?</li>
<li>7.3 Defining Cybercrime
• 7.3.1 Determining the Criteria
• 7.3.2 A Preliminary Definition of Cybercrime
• 7.3.3 Framing a Coherent and Comprehensive Definition of Cybercrime</li>
<li>7.4 Three Categories of Cybercrime: Piracy, Trespass, and Vandalism in Cyberspace</li>
<li>7.5 Cyber‐Related Crimes
• 7.5.1 Some Examples of Cyber‐Exacerbated vs. Cyber‐Assisted Crimes
• 7.5.2 Identity Theft</li>
<li>7.6 Technologies and Tools for Combating Cybercrime
• 7.6.1 Biometric Technologies
• 7.6.2 Keystroke‐Monitoring Software and Packet‐Sniffing Programs</li>
<li>7.7 Programs and Techniques Designed to Combat Cybercrime in the United States
• 7.7.1 Entrapment and “Sting” Operations to Catch Internet Pedophiles
• Scenario 7–2: Entrapment on the Internet
• 7.7.2 Enhanced Government Surveillance Techniques and the Patriot Act</li>
<li>7.8 National and International Laws to Combat Cybercrime
• 7.8.1 The Problem of Jurisdiction in Cyberspace
• Scenario 7–3: A Virtual Casino
• Scenario 7–4: Prosecuting a Computer Corporation in Multiple Countries
• 7.8.2 Some International Laws and Conventions Affecting Cybercrime
• Scenario 7–5: The Pirate Bay Web Site</li>
<li>7.9 Cybercrime and the Free Press: The Wikileaks Controversy
• 7.9.1 Are WikiLeaks’ Practices Ethical?
• 7.9.2 Are WikiLeaks’ Practices Criminal?
• 7.9.3 WikiLeaks and the Free Press</li>
<li>7.10 Chapter Summary</li>
</ul>
<p>• CHAPTER 8: Intellectual Property Disputes in Cyberspace</p>
<ul>
<li>Scenario 8–1: Streaming Music Online</li>
<li>8.1 What Is Intellectual Property?
• 8.1.1 Intellectual Objects
• 8.1.2 Why Protect Intellectual Objects?
• 8.1.3 Software as Intellectual Property
• 8.1.4 Evaluating a Popular Argument Used by the Software Industry to Show Why It Is Morally Wrong to Copy Proprietary Software</li>
<li>8.2 Copyright Law and Digital Media
• 8.2.1 The Evolution of Copyright Law in the United States
• 8.2.2 The Fair‐Use and First‐Sale Provisions of Copyright Law
• 8.2.3 Software Piracy as Copyright Infringement
• 8.2.4 Napster and the Ongoing Battles over Sharing Digital Music</li>
<li>8.3 Patents, Trademarks, and Trade Secrets
• 8.3.1 Patent Protections
• 8.3.2 Trademarks
• 8.3.3 Trade Secrets</li>
<li>8.4 Jurisdictional Issues Involving Intellectual Property Laws</li>
<li>8.5 Philosophical Foundations for Intellectual Property Rights
• 8.5.1 The Labor Theory of Property
• Scenario 8–2: DEF Corporation vs. XYZ Inc.
• 8.5.2 The Utilitarian Theory of Property
• Scenario 8–3: Sam’s e‐Book Reader Add‐on Device
• 8.5.3 The Personality Theory of Property
• Scenario 8–4: Angela’s B++ Programming Tool</li>
<li>8.6 The “Free Software” and “Open Source” Movements
• 8.6.1 GNU and the Free Software Foundation
• 8.6.2 The “Open Source Software” Movement: OSS vs. FSF</li>
<li>8.7 The “Common Good” Approach: An Alternative Framework for Analyzing the Intellectual Property Debate
• 8.7.1 Information Wants to be Shared vs. Information Wants to be Free
• 8.7.2 Preserving the Information Commons
• 8.7.3 The Fate of the Information Commons: Could the Public Domain of Ideas Eventually Disappear?
• 8.7.4 The Creative Commons</li>
<li>8.8 PIPA, SOPA, and RWA Legislation: Current Battlegrounds in the Intellectual Property War
• 8.8.1 The PIPA and SOPA Battles
• 8.8.2 RWA and Public Access to Health‐Related Information
• Scenario 8–5: Elsevier Press and “The Cost of Knowledge” Boycott
• 8.8.3 Intellectual Property Battles in the Near Future</li>
<li>8.9 Chapter Summary</li>
</ul>
<p>• CHAPTER 9: Regulating Commerce and Speech in Cyberspace</p>
<ul>
<li>Scenario 9–1: Anonymous and the Ku Klux Klan</li>
<li>9.1 Introduction and Background Issues: Some Key Questions and Critical Distinctions Affecting Internet Regulation
• 9.1.1 Is Cyberspace a Medium or a Place?
• 9.1.2 Two Categories of Cyberspace Regulation: Regulating Content and Regulating Process
• 9.1.3 Four Modes of Regulation: The Lessig Model</li>
<li>9.2 Digital Rights Management (DRM)
• 9.2.1 Some Implications of DRM for Public Policy Debates Affecting Copyright Law
• 9.2.2 DRM and the Music Industry
• Scenario 9–2: The Sony Rootkit Controversy</li>
<li>9.3 E‐Mail Spam
• 9.3.1 Defining Spam
• 9.3.2 Why Is Spam Morally Objectionable?</li>
<li>9.4 Free Speech vs. Censorship and Content Control in Cyberspace
• 9.4.1 Protecting Free Speech
• 9.4.2 Defining Censorship</li>
<li>9.5 Pornography in Cyberspace
• 9.5.1 Interpreting “Community Standards” in Cyberspace
• 9.5.2 Internet Pornography Laws and Protecting Children Online
• 9.5.3 Virtual Child Pornography
• 9.5.4 Sexting and Its Implications for Current Child Pornography Laws
• Scenario 9–3: A Sexting Incident Involving Greensburg Salem High School</li>
<li>9.6 Hate Speech and Speech that Can Cause Physical Harm to Others
• 9.6.1 Hate Speech on the Web
• 9.6.2 Online “Speech” that Can Cause Physical Harm to Others</li>
<li>9.7 “Network Neutrality” and the Future of Internet Regulation
• 9.7.1 Defining Network Neutrality
• 9.7.2 Some Arguments Advanced by Net Neutrality’s Proponents and Opponents
• 9.7.3 Future Implications for the Net Neutrality Debate</li>
<li>9.8 Chapter Summary</li>
</ul>
<p>• CHAPTER 10: The Digital Divide, Democracy, and Work</p>
<ul>
<li>Scenario 10–1: Digital Devices, Social Media, Democracy, and the “Arab Spring”</li>
<li>10.1 The Digital Divide
• 10.1.1 The Global Digital Divide
• 10.1.2 The Digital Divide within Nations
• Scenario 10–2: Providing In‐Home Internet Service for Public School Students
• 10.1.3 Is the Digital Divide an Ethical Issue?</li>
<li>10.2 Cybertechnology and the Disabled</li>
<li>10.3 Cybertechnology and Race
• 10.3.1 Internet Usage Patterns
• 10.3.2 Racism and the Internet</li>
<li>10.4 Cybertechnology and Gender
• 10.4.1 Access to High‐Technology Jobs
• 10.4.2 Gender Bias in Software Design and Video Games</li>
<li>10.5 Cybertechnology, Democracy, and Democratic Ideals
• 10.5.1 Has Cybertechnology Enhanced or Threatened Democracy?
• 10.5.2 How has Cybertechnology Affected Political Elections in Democratic Nations?</li>
<li>10.6 The Transformation and the Quality of Work
• 10.6.1 Job Displacement and the Transformed Workplace
• 10.6.2 The Quality of Work Life in the Digital Era
• Scenario 10–3: Employee Monitoring and the Case of Ontario vs. Quon</li>
<li>10.7 Chapter Summary</li>
</ul>
<p>• CHAPTER 11: Online Communities, Virtual Reality, and Artificial Intelligence</p>
<ul>
<li>Scenario 11–1: Ralph’s Online Friends and Artificial Companions</li>
<li>11.1 Online Communities and Social Networking Services
• 11.1.1 Online Communities vs. Traditional Communities
• 11.1.2 Blogs and Some Controversial Aspects of the Blogosphere
• Scenario 11–2: “The Washingtonienne” Blogger
• 11.1.3 Some Pros and Cons of SNSs (and Other Online Communities)
• Scenario 11–3: A Suicide Resulting from Deception on MySpace</li>
<li>11.2 Virtual Environments and Virtual Reality
• 11.2.1 What Is Virtual Reality (VR)?
• 11.2.2 Ethical Aspects of VR Applications</li>
<li>11.3 Artificial Intelligence (AI)
• 11.3.1 What Is AI? A Brief Overview
• 11.3.2 The Turing Test and John Searle’s “Chinese Room” Argument
• 11.3.3 Cyborgs and Human–Machine Relationships</li>
<li>11.4 Extending Moral Consideration to AI Entities
• Scenario 11–4: Artificial Children
• 11.4.1 Determining Which Kinds of Beings/Entities Deserve Moral Consideration
• 11.4.2 Moral Patients vs. Moral Agents</li>
<li>11.5 Chapter Summary</li>
</ul>
<p>• CHAPTER 12: Ethical Aspects of Emerging and Converging Technologies</p>
<ul>
<li>Scenario 12–1: When “Things” Communicate with One Another</li>
<li>12.1 Converging Technologies and Technological Convergence</li>
<li>12.2 Ambient Intelligence (AmI) and Ubiquitous Computing
• 12.2.1 Pervasive Computing, Ubiquitous Communication, and Intelligent User Interfaces
• 12.2.2 Ethical and Social Aspects of AmI
• Scenario 12–2: E. M. Forster’s “(Pre)Cautionary Tale”
• Scenario 12–3: Jeremy Bentham’s “Panopticon/Inspection House” (Thought Experiment)</li>
<li>12.3 Nanotechnology and Nanocomputing
• 12.3.1 Nanotechnology: A Brief Overview
• 12.3.2 Ethical Issues in Nanotechnology and Nanocomputing</li>
<li>12.4 Autonomous Machines
• 12.4.1 What Is an AM?
• 12.4.2 Some Ethical and Philosophical Questions Pertaining to AMs</li>
<li>12.5 Machine Ethics and Moral Machines
• 12.5.1 What Is Machine Ethics?
• 12.5.2 Designing Moral Machines</li>
<li>12.6 A “Dynamic” Ethical Framework for Guiding Research in New and Emerging Technologies
• 12.6.1 Is an ELSI‐Like Model Adequate for New/Emerging Technologies?
• 12.6.2 A “Dynamic Ethics” Model</li>
<li>12.7 Chapter Summary</li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div></div><footer class><p>© 2024 Robinson Raju, All Rights Reserved <br/></p><ul><li><a href="https://github.com/robinsonraju">GitHub</a></li><li><a href="https://scholar.google.com/citations?user=TxqnZk8AAAAJ&amp;hl=en">Google Scholar</a></li><li><a href="https://www.linkedin.com/in/robinsonraju/">LinkedIn</a></li><li><a href="https://substack.com/@robinsonraju">Substack</a></li></ul></footer></div></body><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">
            const socket = new WebSocket('ws://localhost:3001')
            // reload(true) ensures resources like images and scripts are fetched again in firefox
            socket.addEventListener('message', () => document.location.reload(true))
          </script><script src="../postscript.js" type="module"></script></html>