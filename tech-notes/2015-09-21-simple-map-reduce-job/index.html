<!DOCTYPE html>
<html
  lang="en-us"
  prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"
>
  <head>
    <meta charset="utf-8" />

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="HandheldFriendly" content="True" />
<meta name="MobileOptimized" content="320" />
<meta name="viewport" content="width=device-width, initial-scale=1" />


<link rel="apple-touch-icon" sizes="180x180" href="https://robinsonraju.info//apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://robinsonraju.info//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://robinsonraju.info//favicon-16x16.png">
<link rel="manifest" href="https://robinsonraju.info//site.webmanifest">
<link rel="mask-icon" href="https://robinsonraju.info//safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">



<meta name="keywords" content="">

<meta property="og:title" content="Writing a simple Mapper and Reducer for Wordcount" />
<meta property="og:description" content="The last blog was about how to run wordcount using the &ldquo;hadoop-mapreduce-examples." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://robinsonraju.info/tech-notes/2015-09-21-simple-map-reduce-job/" />
<meta property="article:published_time" content="2015-09-21T23:50:11+00:00" />
<meta property="article:modified_time" content="2015-09-21T23:50:11+00:00" /><meta property="og:site_name" content="Rob&#39;s Notes" />

<meta property="og:site_name" content="Robinson Raju" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Writing a simple Mapper and Reducer for Wordcount"/>
<meta name="twitter:description" content="The last blog was about how to run wordcount using the &ldquo;hadoop-mapreduce-examples."/>


<meta itemprop="name" content="Writing a simple Mapper and Reducer for Wordcount">
<meta itemprop="description" content="The last blog was about how to run wordcount using the &ldquo;hadoop-mapreduce-examples.">
<meta itemprop="datePublished" content="2015-09-21T23:50:11&#43;00:00" />
<meta itemprop="dateModified" content="2015-09-21T23:50:11&#43;00:00" />
<meta itemprop="wordCount" content="610">



<meta itemprop="keywords" content="" />


    <title>Writing a simple Mapper and Reducer for Wordcount || Robinson Raju</title>
    <link rel="canonical" href="https://robinsonraju.info/tech-notes/2015-09-21-simple-map-reduce-job/" />

    

    <link rel="stylesheet" href="/css/reboot.css" />
<link rel="stylesheet" href="/css/style.css" />
<link rel="stylesheet" href="/css/syntax.css" />


<link href="https://fonts.googleapis.com/css?family=Lora&display=swap" rel="stylesheet">

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="apple-touch-icon" href="/apple-touch-icon.png" />
  </head>
  <body
  class=" look-sheet-bkg"
  lang="en-us">
  <div class="nav-bkg">
    <nav class="content-container pagewide-bar-padding">
      <span class="divider">/ </span>
      <a href="https://robinsonraju.info/" >Robinson Raju</a>
      <span class="divider">/ </span>
  <a href="https://robinsonraju.info/tech-notes">Technical Notes</a>
      <ul class="list-unstyled right-links">

          <li>
            <a href="/about">
              <span class="post-title">About</span>
            </a>
          </li>

</ul>

    </nav>
  </div>
  <article
    id="main"
    class="content-container look-sheet article-pad-v "
    itemscope
    itemtype="https://schema.org/Article" >
  <meta itemprop="author" content="Robinson Raju" />
  <meta itemprop="publisher" content="Robinson Raju" />
  <meta itemprop="image" content="" />
  <meta itemprop="headline" content="Writing a simple Mapper and Reducer for Wordcount" />
  <h1 itemprop="name" id="title">Writing a simple Mapper and Reducer for Wordcount</h1>

  

    <h4 itemprop="name" id="title">Robinson Raju</h4>

    

    
      <div class="post-tags">
        
          <a href="https://robinsonraju.info/tags/technical-notes/">#Technical Notes</a>&nbsp;
        
          <a href="https://robinsonraju.info/tags/blog/">#Blog</a>&nbsp;
        
      </div>
    

    
      <div class="post-date">
        
          <span itemprop="datePublished">September 21, 2015</span>
          <meta itemprop="dateModified" content="September 21, 2015"/>
        
      | 610 words
      | 3-minute read
      </div>
    
  
  
  <div itemprop="articleBody" id="content" class="article-body margin-top-2em">
    <p>The last blog was about how to run wordcount using the &ldquo;hadoop-mapreduce-examples.jar&rdquo; that was automatically available in the VMs. How would it be to really write the Mapper and Reducer for this? I searched a bit for an eclipse plugin to be able to create a MR project through eclipse that would have the template for Mapper and Reducer and I would just write the implementation. Found some plugins (e.g HDT) and some screencasts but didn&rsquo;t take me far. Remembered that there was an eclipse icon in the Cloudera VM. Started the VM, clicked on the icon and viola ! there was a sample project with Stubs for Mapper, Reducer and Driver. Exactly what I needed!</p>
<img src="/img/hadoop/Stubs.png" width="420"/>
<p>Put in the code for Mapper, Reducer and Driver in the Stub classes and ran the Driver. It worked like a charm. Here is the code for it.</p>
<h2 id="mapper">Mapper</h2>
<p>The map method takes key, value and context as inputs. The key represents the name of a document and the value is the contents of the document. For e.g, a record in a file. The map method below uses StringTokenizer to split the record into words, loops through the words and writes a 2-tuple (word, 1) into the context. Each mapper does this and what we get in the end is a list of key-value pairs.</p>
<pre><code>import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class StubMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();

    @Override
    public void map(LongWritable key, Text value, Context context)
            throws IOException, InterruptedException {

        String line = value.toString();
        StringTokenizer tokenizer = new StringTokenizer(line);
        while (tokenizer.hasMoreTokens()) {
            word.set(tokenizer.nextToken());
            context.write(word, one);
        }

    }
}
</code></pre>
<h2 id="reducer">Reducer</h2>
<p>A reducer takes an input of a key and list of values associated with the key, adds the counts and writes the output to the context.
For e.g, input of (world, 1), (world, 1) gives output as (world, 2).</p>
<pre><code>import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class StubReducer extends
        Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {

    @Override
    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)
            throws IOException, InterruptedException {

        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        context.write(key, new IntWritable(sum));
    }
}
</code></pre>
<h2 id="driver">Driver</h2>
<pre><code>import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

public class StubDriver {

    public static void main(String[] args) throws Exception {

        /*
         * Validate that two arguments were passed from the command line.
         */
        if (args.length != 2) {
            System.out.printf(&quot;Usage: StubDriver &lt;input dir&gt; &lt;output dir&gt;\n&quot;);
            System.exit(-1);
        }

        /*
         * Instantiate a Job object for your job's configuration.
         */
        Job job = new Job();

        /*
         * Specify the jar file that contains your driver, mapper, and reducer.
         * Hadoop will transfer this jar file to nodes in your cluster running
         * mapper and reducer tasks.
         */
        // job.setJarByClass(StubDriver.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        job.setMapperClass(StubMapper.class);
        job.setReducerClass(StubReducer.class);

        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);

        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        /*
         * Specify an easily-decipherable name for the job. This job name will
         * appear in reports and logs.
         */
        job.setJobName(&quot;Stub Driver&quot;);

        /*
         * Start the MapReduce job and wait for it to finish. If it finishes
         * successfully, return 0. If not, return 1.
         */
        boolean success = job.waitForCompletion(true);
        System.exit(success ? 0 : 1);
    }
}
</code></pre>
<h2 id="how-to-run">How to Run</h2>
<pre><code>Create an input directory named &quot;input&quot;

Run As &gt; Java Application (give 2 arguments &quot;input&quot; and &quot;output&quot;)
</code></pre>
<p>Look at the the file &lsquo;part-r-00000&rsquo; in the output directory
<img src="/img/hadoop/wc-output-eclipse.png" width="320"/></p>
<hr>
<h3 id="references">References</h3>
<ul>
<li>QuickStart VMs for CDH 5.4.x. (n.d.). Retrieved September 21, 2015, from <a href="http://www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-4-x.html">http://www.cloudera.com/content/cloudera/en/downloads/quickstart_vms/cdh-5-4-x.html</a></li>
<li>WordCount. (n.d.). Retrieved September 21, 2015, from <a href="https://wiki.apache.org/hadoop/WordCount">https://wiki.apache.org/hadoop/WordCount</a></li>
</ul>
<hr>
<p><em>Header Image - &ldquo;<strong>Words</strong>&rdquo; by Cayce Newell via <a href="https://flic.kr/p/4BsjLY">Flickr</a>.</em></p>

  </div>

</article>

  


  
    <div class="nav-bkg-50 content-container-narrow-pad bottom-links text-0p75">
      <nav class="flex-row">
      
      <a href="https://robinsonraju.info/tech-notes/2015-09-15-wordcount-on-hadoop/" class="flex-row v-center no-underline"  style="max-width:45%;">
        <span class="text-1p5">←</span>&nbsp;<span class="re-underline">Previous: Running Hadoop WordCount example</span>
      </a>
      
      
        <a href="https://robinsonraju.info/tech-notes/2015-09-30-mapreducejob-iris/" class="flex-row v-center no-underline" style="max-width: 45%;">
        <span class="re-underline">Next: A Simple MapReduce Job for Iris Dataset</span>&nbsp;<span class="text-1p5">→</span>
        </a>
      
      </nav>
    </div>
  

  </body>
</html>
